# -*- coding: utf-8 -*-
"""final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-otU7mBJF0dtfGryhLkV0xj_AyWwNY-r

# Comparación Feature Extraction y Todas las Características
### Santiago Mora
### Gabriel Reynoso
### Adamaris de Dios
### Adara Pulido
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import numpy as np
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline

dff = pd.read_csv('/content/drive/MyDrive/ProyectoAnalisisDS/DFPF0803.csv')

from google.colab import drive
drive.mount('/content/drive')

dff.info()

dff.columns

columns = dff.columns
for col in columns:
  print(col, dff[col].unique()) #['DOMINIO', 'POB_E_A', 'POB_L_A', 'VTOT_A', 'P4_1', 'P4_8_2', 'P4_8_3', 'P4_11', 'P4_12_3', 'P4_12_3', 'P6_1_4', 'P6_1_5', 'P12_4', 'P12_5', 'P12_6', 'P12_8', 'P12_9', 'P12_11', 'P12_13', 'P12_14_1', 'P12_14_5', 'P13_1', 'P13_6', 'P13_8', 'P13_1_1_2', 'P13_1_1_6', 'P13_1_1_7', 'P13_1_1_13', 'P13_1_2_3', 'P13_1_2_7', 'P13_1_2_8', 'P13_1_3_2', 'P13_1_4_2', 'P14_1_10', 'P14_1_11', 'P14_1_14', 'P14_1_17', 'P14_1_26', 'P14_1_29', 'P16_1_5', 'P16_2_1', 'P16_3_4_1', 'P17_1_1_1', 'PE5_1', 'PE5_3', 'PE5_5', 'PE5_7', 'PE5_12', 'PE5_14', 'PE5_15']

"""División de variables independientes y variable objetivo"""

cols = ['VPAR_12M', 'DOMINIO', 'POB_E_A', 'POB_L_A', 'VTOT_A', 'P4_1', 'P4_8_2', 'P4_8_3', 'P4_11', 'P4_12_3', 'P6_1_4', 'P6_1_5', 'P12_4', 'P12_5', 'P12_6', 'P12_8', 'P12_9', 'P12_11', 'P12_13', 'P12_14_1', 'P12_14_5', 'P13_1', 'P13_6', 'P13_8', 'P13_1_1_2', 'P13_1_1_6', 'P13_1_1_7', 'P13_1_1_13', 'P13_1_2_3', 'P13_1_2_7', 'P13_1_2_8', 'P13_1_3_2', 'P13_1_4_2', 'P14_1_10', 'P14_1_11', 'P14_1_14', 'P14_1_17', 'P14_1_26', 'P14_1_29', 'P16_1_5', 'P16_2_1', 'P16_3_4_1', 'P17_1_1_1', 'PE5_1', 'PE5_3', 'PE5_5', 'PE5_7', 'PE5_12', 'PE5_14', 'PE5_15']
dff = dff[cols]

dff.info()

X = dff.drop(columns = 'VPAR_12M')
y = dff["VPAR_12M"]

"""Seleccion de variables numéricas y variables categóricas"""

num_vars = X[['P13_1', 'P13_6', 'P13_8']].columns
cat_vars = X.drop(columns = ['P13_1', 'P13_6', 'P13_8']).columns

"""Obtención de las categorías de las variables categóricas codificadas"""

enc = OneHotEncoder()
enc = enc.fit(X[cat_vars])
categories = enc.categories_

pre_processing = make_column_transformer((StandardScaler(), num_vars),
                                         (OneHotEncoder(drop = 'first', categories = categories), cat_vars))

"""División del conjunto de datos en conjuntos de entrenamiento y prueba"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 1234)

"""Modelo de regresión logística"""

lr = LogisticRegression(solver='saga', max_iter = 10000)

lr_pipeline = make_pipeline(pre_processing, lr)

lr_fitted = lr_pipeline.fit(X_train, y_train)

"""Precisión del modelo"""

lr_pipeline.score(X_test, y_test)

print("El intercepto del modelo es: ", lr_pipeline.named_steps["logisticregression"].intercept_)
print("Los coeficientes del modelo son: ", lr_pipeline.named_steps["logisticregression"].coef_)

"""Selección de características

Método de envoltura
"""

from mlxtend.feature_selection import SequentialFeatureSelector as SFS
sfs = SFS(lr,
          k_features = 20,
          forward = True,
          #floating = False,
          scoring = 'accuracy',
          cv = 2,
          n_jobs = -1
)
sfs = sfs.fit(X_train.drop(columns = 'DOMINIO'), y_train)

pd.DataFrame.from_dict(sfs.get_metric_dict()).T

featsel = pd.DataFrame.from_dict(sfs.get_metric_dict()).T

featsel.to_csv('/content/drive/MyDrive/ProyectoAnalisisDS/featsel.csv')

"""# Con mayor score de feature selection (5 features)"""

cols = ['VTOT_A', 'P12_4', 'P14_1_10', 'P14_1_17', 'P14_1_29']
X = dff[cols]
y = dff["VPAR_12M"]

enc = OneHotEncoder()
enc = enc.fit(X)
categories = enc.categories_

pre_processing = (OneHotEncoder(drop = 'first', categories = categories))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 1234)

"""Modelo de regresión logística"""

lr = LogisticRegression(solver='saga', max_iter = 10000)

lr_pipeline = make_pipeline(pre_processing, lr)

lr_fitted = lr_pipeline.fit(X_train, y_train)

"""Precisión del modelo"""

lr_pipeline.score(X_test, y_test)

print("El intercepto del modelo es: ", lr_pipeline.named_steps["logisticregression"].intercept_)
print("Los coeficientes del modelo son: ", lr_pipeline.named_steps["logisticregression"].coef_)

"""# Con 20 features de feature selection"""

cols = ['POB_E_A',
 'POB_L_A',
 'VTOT_A',
 'P4_8_2',
 'P4_8_3',
 'P4_12_3',
 'P6_1_5',
 'P12_4',
 'P12_14_5',
 'P13_1_1_7',
 'P14_1_10',
 'P14_1_17',
 'P14_1_26',
 'P14_1_29',
 'PE5_1',
 'PE5_3',
 'PE5_5',
 'PE5_7',
 'PE5_12',
 'PE5_14']

X = dff[cols]
y = dff["VPAR_12M"]

enc = OneHotEncoder()
enc = enc.fit(X)
categories = enc.categories_

pre_processing = (OneHotEncoder(drop = 'first', categories = categories))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 1234)

"""Modelo de regresión logística"""

lr = LogisticRegression(solver='saga', max_iter = 10000)

lr_pipeline = make_pipeline(pre_processing, lr)

lr_fitted = lr_pipeline.fit(X_train, y_train)

"""Precisión del modelo"""

lr_pipeline.score(X_test, y_test)

print("El intercepto del modelo es: ", lr_pipeline.named_steps["logisticregression"].intercept_)
print("Los coeficientes del modelo son: ", lr_pipeline.named_steps["logisticregression"].coef_)